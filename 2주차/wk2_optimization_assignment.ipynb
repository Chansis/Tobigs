{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EP3O4xptLMay",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oByQ9wXHLMay",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IySSjlizLMaz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "075EQI1bLMa0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)\n",
    "\n",
    "# train data =75%, test data = 25%\n",
    "# random_state = 0 : 수행할 때마다 동일한 데이터 생성, 설정하지 않으면 수행할 때마다 다른 데이터를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "O8Ht5u8kLMa1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UI0Xy0gHLMa3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]    #bias collum과 index 유지\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xBsUSCGGLMa3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m9sP3nzlLMa4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qz7xz9dbLMa4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9996911 , 0.94014585, 0.67107508])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2y05lS6xLMa5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-x_{i}\\theta}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2awM57u5LMa5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X,parameters)\n",
    "    p = 1/(1+np.exp(-z))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WVaZEwrdLMa5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950876156684271"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = - \\Sigma(y_{i}\\log p(X_{i}) + (1 - y_{i}) \\log(1 - p(X_{i}))) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FnGRAur3LMa6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = (y * np.log(p) + (1 - y) * np.log(1-p))\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "C922eXYyLMa6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = np.dot(X ,parameters.T)\n",
    "    loss = ((y - y_hat)**2) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0j-MhGkyLMa6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss / n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uSkPS5olLMa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5763507639455618"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=$ $ -\\Sigma(y_{i} - \\theta^{T}X_{i})X_{ij} $\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=$ $ -\\Sigma(y_{i} - p_{i})X_{ij} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "apZ0Miz5LMa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = np.dot(X, parameters.T)\n",
    "        gradient = (y - y_hat) * X[j]\n",
    "    else:\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = (y - p) * X[j]\n",
    "    return -gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XXBe6q8gLMa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0749945183132031"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$ \\alpha^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Qby2_X1vLMa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rHxBS5RnLMa8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57.07820843910687, 17.474722772549168, 46.82491530117679]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LgnfT6eHLMa8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명: batch_size는 학습에 사용되는 데이터의 크기를 의미한다. batch_size가 X_train의 크기와 같다면 X_train 전체를 한번의 학습에 사용한다는 의미이다. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "    \n",
    "    parameters -= gradients\n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:  현재 반복 횟수\n",
    "- num_epoch: 총 학습 횟수\n",
    "<br>\n",
    "\n",
    "BGD: 모든 데이터셋의 기울기를 학습 한번에 구함 <br>\n",
    "SGD: 임의의 1개의 데이터에 대해서 한번의 학습동안 기울기를 구함 <br>\n",
    "MGD: 데이터셋의 일부에 대해서 학습 한번 동안 기울기를 구함\n",
    "<br>\n",
    "\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> SGD  \n",
    "batch_size=k -> MGD \n",
    "<br>\n",
    "batch_size=whole -> BGD "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)    #train_data의 독립변수의 수만큼 랜덤한 파라미터 설정 \n",
    "    \n",
    "    #로지스틱 회귀는 목적함수로 minus_log_cross_entropy_i, 선형회귀는 mse_i\n",
    "    if model == 'logistic':\n",
    "        loss_function = minus_log_cross_entropy_i \n",
    "    else:\n",
    "        loss_function = mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건             \n",
    "            # 새로운 손실 함수와 기존 손실함수의 차이가 tolerance보다 작다면 학습을 중단\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train, batch_size = X_train.shape[0])\n",
    "new_param_bgd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, batch_size = 1)\n",
    "new_param_sgd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, batch_size = 32)\n",
    "new_param_mgd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict Label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BGD 활용 예측\n",
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "        \n",
    "#초기 설정한 random_parameter로 예측\n",
    "        y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, model = 'linear')\n",
    "new_param"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Ii3zBOwSLMa_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "UoEACrbYLMbA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijgIcAdGLMbA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}