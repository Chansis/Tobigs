{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Framework와 Library의 가장 큰 차이점은 제어 흐름의 주도성에 있다. 프레임워크는 코드의 흐름이 정해져 있고, 사용자가 프레임워크 안에 들어가서 필요한 코드를 짜 넣는 반면에 라이브러리는 사용자가 라이브러리를 가져다가 사용하고 호출하는 형태이다. 라이브러리는 함수들이나 기능의 모음을 가져다가 쓰는 것이고, 프레임워크는 특정 디자인 패턴이나, 전처리 후처리에 필요한 동작과 기능들을 수행하기 위해서 프레임워크가 실행되다가 중간중간 특정 구현 단에서만 사용자의 코드를 검색하여 사용하는 형태이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "인간은 수많은 학습을 하면서 세상의 기본적인 개념을 익히며 성장한다. 기계의 학습은 이러한 인간의 학습 과정을 모방한 것이다. 인간이 수많은 예시를 통해 학습한 것처럼 기계가 학습하기 위해서도 많은 예시(데이터)가 필요하다. 데이터가 갖춰지면 기계가 학습을 하기 위한 학습모델이 필요하다. 머신러닝과 딥러닝의 차이는 여기서 발생한다. 기계학습은 계산적인 방법으로 수학적으로 정의된 회귀, 분류, 군집의 개념을 이용하는 반면 딥러닝은 인간의 신경망을 모방한 인공신경망을 통해 학습한다. 머신러닝은 학습의 과정을 수학적으로 정확히 계산하고 예측하여 어떠한 방식으로 학습이 이루어지는지 알 수 있지만, 딥러닝의 경우 히든 레이어 안에서 어떻게 학습이 일어나는지 어떤 요인으로 인해 학습이 발전하는지 모델링할 수 없다.  학습 과정에서도 차이점이 있는데 머신러닝은 엔지니어가 미리 각 데이터를 라벨링하여야 하는 반면에 딥러닝은 데이터들이 주어지면 자동으로 데이터를 군집화하고 분류한다. 기존 머신러닝에 치우쳤던 인공지능 분야가 딥러닝으로 발전하게 된 이유는 복잡한 알고리즘을 훈련할 수 있는 풍부한 데이터와 컴퓨터 성능의 향상이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "#CUDA 설치 여부 확인 및 CUDA 미설치 시에 CPU 사용 코드\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "#학습 매개변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Dataset 불러오기\n",
    "# (MNIST dataset : grayscale의 28*28이미지와 10개 분류 중 하나인 정답으로 이루어진 데이터셋)\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST', #데이터가 저장되는 경로\n",
    "    train = True,          #학습용 혹은 테스트용 데이터셋 여부 지정\n",
    "    download = True,       #root에 데이터가 없을 경우 인터넷에서 다운로드\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() \n",
    "    ])                     #feature와 label transform 지정\n",
    ")#훈련 MNIST 데이터셋 불러오기\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")#훈련 후에 성능 평가를 위한 테스트 MNIST 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size) #batch size : 배치의 크기(50개의 데이터에 batch_size가 10이라면 5번의 iteration 후에 모든 데이터를 볼 수 있음)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "#torch.utils.data.DataLoader : 데이터셋을 배치사이트 형태로 만들어 실제 학습할 때 이용할 수 있게 만들어주는 라이브러리, 샘플들을 미니배치로 전달 (shuffle = True 형태로 셔플의 유무도 지정가능)\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "#데이터셋의 인덱스, 형태, 원소 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module): #CNN 모델\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__()\n",
    "        #첫번쨰 2D 합성곱 계층\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  #1개의 입력 체널(이미지)를 받아들이고 사각 커넬 사이즈가 5인 10개의 합성곱 특징들을 출력\n",
    "        #두번쨰 2D 합성곱 계층\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  #10개의 입력 체널(이미지)를 받아들이고 사각 커넬 사이즈가 5인 20개의 합성곱 특징들을 출력\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) #인접한 픽셀들은 입력확률에 따라 모두 0 값을 가지거나 유효한 값이 되도록 만듦, inplace가 True일 경우 기존 input 값도 0으로 바꾼다.\n",
    "        self.mp = nn.MaxPool2d(2) #사각 커넬 사이즈가 2인 MaxPooling layer\n",
    "        self.fc1 = nn.Linear(320,100) #첫번쨰 fully connected layer\n",
    "        self.fc2 = nn.Linear(100,10) #두번쨰 fully connected layer\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x)))  #X1->Conv1 layer-Relu activation fuction-MaxPooling layer->X2\n",
    "        x = F.relu(self.mp(self.conv2(x)))  #X2->Conv2 layer-Relu activation fuction-MaxPooling layer->X3\n",
    "        x = self.drop2D(x) #X3 dropout 하여 overfitting 줄임\n",
    "        x = x.view(x.size(0), -1)       #출력값 확인\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)         #출력값 확률값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = ConvNet().to(device) \n",
    "criterion = nn.CrossEntropyLoss().to(device)   #cross entropy loss 계산\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) #Adam optimizer 사용, optimizer는 학습에서 loss를 계산하고 loss function의 최소값을 찾는 과정에서 사용된다. Adam optimizer는 이전의 gradient와 현재 gradient를 모두 사용하는 방법으로 lr 소실 문제를 해결하고, 각 파라미터마다 다른 크기의 업데이트를 적용한다. learning_rate를 통해 gradient 계산의 다음 스텝까지의 거리 델타 x 값을 지정 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#학습이 진행되는 코드\n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0    #cost 0으로 초기화\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(data)\n",
    "        cost = criterion(hypothesis, target)   #model을 통해 출력된 값과 target 사이의 오차 계산\n",
    "        cost.backward()          #가중치와 편향에 대한 기울기 계산\n",
    "        optimizer.step()         #optimize로 기울기 업데이트\n",
    "        avg_cost += cost / len(train_loader) \n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ecaluate model\n",
    "model.eval() #train과 evaluate 사이에 다르게 동작하는 layer의 동작을 바꿈(Dropout,BatchNorm 등의 layer)\n",
    "with torch.no_grad(): #gradient 연산 옵션을 꺼서 메모리 사용량 줄이고 연산속도 높임며 결과값을 볼때 사용\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() \n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "     #model의 accuracy 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}